{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”„ Build an ML Pipeline with scikit-learn & Union\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github.com/unionai-oss/bert-llm-classification-pipeline/blob/main/tutorial.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "This tutorial will walk you through building an end-to-end machine learning pipeline using scikit-learn and Union's AI workflow and inference platform. We'll download a dataset, train a machine learning model, deploy it, and track its artifacts using Union's powerful MLOps features. Although this example may seem relatively simple, all the concepts and tools used here can be applied to more complex machine learning and AI projects.\n",
    "\n",
    "\n",
    "By just adding a few lines of code to your Python functions, you'll be able to create a reproducible ML pipeline, taking advantage of Union's features:\n",
    "\n",
    "- Reproducible AI workflows: Ensure your ML pipeline produces the same environments every time.\n",
    "- Versioning of code and artifacts: Track changes in your code and models automatically.\n",
    "- Data Caching for faster iterations: Reuse results from previous executions to save time.\n",
    "- Declarative Infrastructure: Define your ML infrastructure needs directly in your code without worrying about provisioning.\n",
    "- Artifact Management for models and data: Automatically manage your model files and datasets.\n",
    "- Container Image Builder: Build and deploy your code in a consistent environment.\n",
    "- Local Development: Test your workflows locally before deploying them to the cloud.\n",
    "- Actors for long-running stateful containers: Handle tasks that require continuous state or interaction.\n",
    "- And more...\n",
    "\n",
    "```python\n",
    "@task(\n",
    "    cache=True,\n",
    "    cache_version=\"4\",\n",
    "    container_image=image,\n",
    "    requests=Resources(cpu=\"2\", mem=\"2Gi\")\n",
    ")\n",
    "def download_data(): -> pd.DataFrame:\n",
    "    ...\n",
    "\n",
    "@task(\n",
    "    container_image=image,\n",
    "    requests=Resources(cpu=\"2\", mem=\"20Gi\", gpu=\"1\")\n",
    ")\n",
    "def train_model(data: pd.DataFrame:): -> pytorch.Model:\n",
    "    ...\n",
    "\n",
    "@workflow()\n",
    "def pipeline_workflow():\n",
    "    data = download_data()\n",
    "    train_model(data=data)\n",
    "    ...\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "## ðŸ§° Setup \n",
    "\n",
    "Sign up for a Union Serverless account at [Union.ai](https://union.ai) by clicking the \"Get Started\" button. No card required, and you'll get $30 in free credits to get started. Signing up can take a few minutes.\n",
    "\n",
    "Or you can use your [Union BYOC Enterprise](https://www.union.ai/pricing) login if you have one.\n",
    "\n",
    "### ðŸ“¦ Install Python Packages & Clone Repo\n",
    "\n",
    "Packages can be installed in your local environment using the following command using your preferred package manager from the [requirements.txt](requirements.txt) file. For example `pip install -r requirements.txt`. \n",
    "\n",
    "to clone the repo, run the following command in your environment: `git clone `\n",
    "\n",
    "If you're running this notebook in a Google Colab environment, you can install the packages and clone the GitHub repo directly in the notebook by running the following cell:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
