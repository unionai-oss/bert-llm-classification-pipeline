{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔄 Fine-Tune and Serve LLMs with Union.ai: A Hands-On Tutorial\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/unionai-oss/bert-llm-classification-pipeline/blob/main/tutorial.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "Welcome to this step-by-step tutorial on building a **Large Language Model (LLM) fine-tuning pipeline** using **Hugging Face Transformers** and **Union.ai’s AI workflow and inference platform**. In this tutorial, you’ll train a **BERT-based model for text classification**, serve it for inference, and track every step of your pipeline using **Union’s powerful MLOps capabilities**.  \n",
    "\n",
    "This example might seem simple, but the **core concepts and tools** covered here apply to real-world **AI and machine learning (ML) projects** at any scale. By following along, you'll gain hands-on experience in:  \n",
    "\n",
    "🔸 **Automating ML workflows** with Union.ai  \n",
    "🔸 **Fine-tuning a transformer model** with Hugging Face  \n",
    "🔸 **Deploying a model for inference** and tracking artifacts  \n",
    "🔸 **Optimizing your pipeline** with caching and versioning  \n",
    "\n",
    "## ✨ Why Use Union.ai?  \n",
    "\n",
    "By just adding a few lines of code to your Python functions, you'll be able to create a reproducible ML pipeline, taking advantage of Union's features:\n",
    "\n",
    "With just **a few lines of code**, you can transform your Python functions into **scalable, reproducible AI workflows**. Here’s what you get:  \n",
    "\n",
    "- **🛠 Reproducible AI Workflows** – Ensure your pipeline runs in the same environment every time.  \n",
    "- **📌 Versioning & Tracking** – Automatically track **code, models, and artifacts**.  \n",
    "- **⚡ Faster Iterations with Data Caching** – Reuse previous results to speed up experiments.  \n",
    "- **🖥 Declarative Infrastructure** – Define ML infrastructure **in code** without manual setup.  \n",
    "- **📂 Artifact Management** – Keep track of model checkpoints and datasets seamlessly.  \n",
    "- **📦 Containerized Execution** – Deploy models in a consistent environment with automatic **image building**.  \n",
    "- **🧑‍💻 Local & Cloud Development** – Test locally before scaling up.  \n",
    "- **🎭 Actors for Long Running Stateful Containers** – Run **Effceint batch inference** with persistent containers.  \n",
    "- **…and much more!** \n",
    "\n",
    "## 📝 What You'll Build  \n",
    "\n",
    "By the end of this tutorial, you'll have a **fully functional AI pipeline** that:  \n",
    "\n",
    "1. **Downloads and processes a dataset** 📥  \n",
    "2. **Fine-tunes a BERT model for classification** 🏋️‍♂️  \n",
    "3. **Saves and versions the trained model** 💾  \n",
    "4. **Deploys the model for real-time inference** 🚀  \n",
    "5. **Tracks all artifacts and experiments** using Union.ai 📊  \n",
    "\n",
    "\n",
    "\n",
    "## 🧰 Setup \n",
    "\n",
    "\n",
    "To get started, sign up for a **Union Serverless** account at [Union.ai](https://union.ai) by clicking the **\"Get Started\"** button. No credit card is required, and you'll receive **$30 in free credits** to begin experimenting. The signup process takes just a few minutes.  \n",
    "\n",
    "Alternatively, if you have access to a **[Union BYOC Enterprise](https://www.union.ai/pricing)** account, you can log into your account.  \n",
    "\n",
    "### 📦 Install Python Packages & Clone Repo\n",
    "\n",
    "Packages can be installed in your local environment using the following command using your preferred package manager from the [requirements.txt](requirements.txt) file. For example `pip install -r requirements.txt`. \n",
    "\n",
    "to clone the repo, run the following command in your environment: `git clone https://github.com/unionai-oss/bert-llm-classification-pipeline`\n",
    "\n",
    "If you're running this notebook in a Google Colab environment, you can install the packages and clone the GitHub repo directly in the notebook by running the following cell:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    !git clone https://github.com/unionai-oss/bert-llm-classification-pipeline\n",
    "    %cd bert-llm-classification-pipeline\n",
    "    !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 🔐 Authenticate\n",
    "To use **Union.ai**, you'll need to authenticate your account. Follow the appropriate step based on your setup:  \n",
    "\n",
    "##### 🔸 **Using Union BYOC Enterprise**  \n",
    "\n",
    "If you're using a **[Union BYOC Enterprise](https://www.union.ai/pricing)** account, log in with the following command:  \n",
    "```bash\n",
    "union create login --host <union-host-url>\n",
    "```\n",
    "\n",
    "Replace <union-host-url> with your organization's Union instance URL.\n",
    "\n",
    "##### 🔸 Using Union Serverless\n",
    "If you're using [Union Serverless](https://www.union.ai/) , authenticate by running the command below:\n",
    "\n",
    "Create an account for free at [Union.ai](https://union.ai) if you don't have one yet:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🌟 Authenticate to union serverless\n",
    "!union create login --serverless --auth device-flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧩 Create a Simple Workflow\n",
    "\n",
    "Before we build our ML pipeline lets build a simple workflow to understand the basics of Union's workflow system.\n",
    "\n",
    "`ImageSpec` - Allows you to specify the environment in which your task will run directly in your Python code. This includes the Python packages, CUDA version, and any additional environment setup you need. When a task is run, Union will automatically build a container image with the specified environment if it doens't already exsist and run the task in that container.\n",
    "\n",
    "`Tasks` - Tasks are the building blocks of workflows. They allow you to define a unit of work and what infrastructure to us.\n",
    "\n",
    "`Workflows` - A workflow is a collection of tasks that and defines data flow. Workflows can be run locally or in the cloud.\n",
    "\n",
    "Both tasks workflows are strongly typed\n",
    "\n",
    "Note: We could build our whole ML pipeline directly in the notebook like below if we wanted to!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flytekit as fl\n",
    "import sys\n",
    "\n",
    "image = fl.ImageSpec(\n",
    "    name=\"notebook-example\",\n",
    "    packages=[\n",
    "        \"flytekit==1.15.0\",\n",
    "        \"union==0.1.144\",\n",
    "    ],\n",
    "    python_version=f\"{sys.version_info.major}.{sys.version_info.minor}\",\n",
    "    builder=\"union\",\n",
    ")\n",
    "\n",
    "@fl.task(container_image=image, \n",
    "         requests=fl.Resources(cpu=\"1\", mem=\"1Gi\"))\n",
    "def hello_world(name: str) -> str:\n",
    "    \"\"\"Returns a greeting.\"\"\"\n",
    "    return f\"Hello, {name}!\"\n",
    "\n",
    "@fl.workflow\n",
    "def my_workflow(name: str =\"union.ai\") -> str:\n",
    "    return hello_world(name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from union.remote import UnionRemote\n",
    "serverless = UnionRemote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exe = serverless.execute(my_workflow, inputs={\"name\": \"Flyte\"})\n",
    "exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exe.wait(poll_interval=1)\n",
    "response = exe.outputs['o0']\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔀 BERT Fine-Tuning Pipeline  \n",
    "\n",
    "In this section, we'll execute **tasks and workflows** defined in Python under the relevant folders.  \n",
    "\n",
    "📂 Navigate to the `tasks` and `workflows` folders to explore the code. If you're following along in a **hosted Jupyter Notebook**, you can view the files by clicking the **folder icon** (usually on the left side of the screen).  \n",
    "\n",
    "### 🛠 Workflow Overview  \n",
    "\n",
    "We’ll create an **end-to-end machine learning pipeline** to train a **BERT model for text classification** using the **Iris dataset**. The workflow consists of the following steps:  \n",
    "\n",
    "1. 📥 **Download & Preprocess Dataset**   \n",
    "2. 🤖 **Download Pretrained BERT Model**   \n",
    "3. 🏋️‍♂️ **Fine-tune BERT Model**   \n",
    "4. 📊 **Evaluate Model Performance**   \n",
    "5. 💾 **Save Model as an Artifact**  *(We’ll serve the model in the next section)*  \n",
    "6. 🔍 **Run a Prediction on New Test Data**   \n",
    "\n",
    "> **💡 Note:**  \n",
    "> In more complex ML workflows, **data pipelines** are often separate from **model training pipelines**.  \n",
    "> For simplicity, we'll combine them into a single workflow in this example.  \n",
    "\n",
    "### 🔎 Explore the Code  \n",
    "\n",
    "To view the workflow, navigate to the [`workflows/train_pipeline.py`](workflows/train_pipeline.py) file.  \n",
    "\n",
    "- Look for the **`train_pipeline()`** function—this defines the full workflow.  \n",
    "- The workflow **calls tasks** from the [`tasks`](tasks/) folder.  \n",
    "- It also **builds a container image** using [`containers.py`](containers.py).  \n",
    "\n",
    "Once you understand the structure, **run the workflow** and track your pipeline execution with **Union.ai**! 🚀  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🌟 Run the bert training pipeline using LoRA, QLoRA or FFT\n",
    "!union run --remote workflows/train_pipeline.py train_pipeline --epochs 3 --tuning_method lora "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the command above to run the workflow. This will automatically build the container image and run the tasks in the workflow. You can view the progress and logs in the Union UI. \n",
    "\n",
    "We'll go through each workflows and tasks in detail below. Tasks are defined in the `tasks` folder. Workflows are defined in the `workflows` folder.\n",
    "\n",
    "These were already cloned in the setup step above. If you are running this in a local environment, make sure to clone the repo and install the requirements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile workflows/train_pipeline.py\n",
    "\n",
    "\"\"\"\n",
    "This file contains the train_pipeline workflow that orchestrates the\n",
    "training pipeline for BERT classification models\n",
    "\"\"\"\n",
    "\n",
    "from union import workflow\n",
    "\n",
    "from tasks.data import download_dataset, visualize_data\n",
    "from tasks.inference import predict_batch_sentiment\n",
    "from tasks.model import download_model, evaluate_model, train_model\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# train pipeline\n",
    "# ---------------------------\n",
    "@workflow\n",
    "def train_pipeline(\n",
    "    tuning_method: str = \"lora\",  # options: \"full\", \"lora\", \"qlora\"\n",
    "    model_name: str = \"distilbert-base-uncased\",\n",
    "    epochs: int = 3,\n",
    "    extra_test_text: list[str] = [\n",
    "        \"This is a great movie!\",\n",
    "        \"This is a bad movie!\",\n",
    "    ],\n",
    ") -> None:\n",
    "\n",
    "    train_dataset, val_dataset, test_dataset = download_dataset()\n",
    "    saved_model_dir = download_model(model_name=model_name)\n",
    "\n",
    "    visualize_data(\n",
    "        train_dataset=train_dataset, val_dataset=val_dataset, test_dataset=test_dataset\n",
    "    )\n",
    "\n",
    "    trained_model_dir = train_model(\n",
    "        tuning_method=tuning_method,\n",
    "        model_dir=saved_model_dir,\n",
    "        train_dataset=train_dataset,\n",
    "        val_dataset=val_dataset,\n",
    "        epochs=epochs,\n",
    "    )\n",
    "\n",
    "    evaluate_model(trained_model_dir=trained_model_dir, test_dataset=test_dataset)\n",
    "\n",
    "    # Perform batch inference\n",
    "    predict_batch_sentiment(trained_model_dir=trained_model_dir, texts=extra_test_text)\n",
    "\n",
    "# Run model training pipeline:\n",
    "#!union run --remote workflows/train_pipeline.py train_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile tasks/data.py\n",
    "\n",
    "\"\"\"\n",
    "This module contains tasks for downloading the dataset and visualizing the data.\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from datasets import Dataset\n",
    "from flytekit.types.directory import FlyteDirectory\n",
    "from flytekit.types.file import FlyteFile\n",
    "from typing_extensions import Annotated\n",
    "from union import Artifact, Deck, Resources, current_context, task\n",
    "\n",
    "from containers import container_image\n",
    "\n",
    "# Define Artifact Specifications\n",
    "RawImdbDataset = Artifact(name=\"raw_imdb_dataset\")\n",
    "TrainImdbDataset = Artifact(name=\"train_imdb_dataset\")\n",
    "ValImdbDataset = Artifact(name=\"val_imdb_dataset\")\n",
    "TestImdbDataset = Artifact(name=\"test_imdb_dataset\")\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# download dataset\n",
    "# ---------------------------\n",
    "@task(\n",
    "    container_image=container_image,\n",
    "    cache=True,\n",
    "    cache_version=\"1\",\n",
    "    requests=Resources(cpu=\"2\", mem=\"2Gi\"),\n",
    ")\n",
    "def download_dataset() -> tuple[\n",
    "    Annotated[FlyteFile, TrainImdbDataset],\n",
    "    Annotated[FlyteFile, ValImdbDataset],\n",
    "    Annotated[FlyteFile, TestImdbDataset],\n",
    "]:\n",
    "\n",
    "    import pandas as pd\n",
    "    from datasets import load_dataset\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    # Load IMDB dataset\n",
    "    dataset = load_dataset(\"imdb\")\n",
    "    train_df = dataset[\"train\"].to_pandas()\n",
    "    test_df = dataset[\"test\"].to_pandas()\n",
    "\n",
    "    # Split training set into train and validation sets\n",
    "    train_df, val_df = train_test_split(\n",
    "        train_df, test_size=0.2, stratify=train_df[\"label\"], random_state=42\n",
    "    )\n",
    "\n",
    "    working_dir = Path(current_context().working_directory)\n",
    "    data_dir = working_dir / \"data\"\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Save datasets as CSV files\n",
    "    train_path = data_dir / \"train.csv\"\n",
    "    val_path = data_dir / \"val.csv\"\n",
    "    test_path = data_dir / \"test.csv\"\n",
    "\n",
    "    train_df.to_csv(train_path, index=False)\n",
    "    val_df.to_csv(val_path, index=False)\n",
    "    test_df.to_csv(test_path, index=False)\n",
    "\n",
    "    return (\n",
    "        TrainImdbDataset.create_from(train_path),\n",
    "        ValImdbDataset.create_from(val_path),\n",
    "        TestImdbDataset.create_from(test_path),\n",
    "    )\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# visualize data\n",
    "# ---------------------------\n",
    "@task(\n",
    "    container_image=container_image,\n",
    "    enable_deck=True,\n",
    "    requests=Resources(cpu=\"2\", mem=\"2Gi\"),\n",
    ")\n",
    "def visualize_data(\n",
    "    train_dataset: FlyteFile, val_dataset: FlyteFile, test_dataset: FlyteFile\n",
    "):\n",
    "    import base64\n",
    "    from textwrap import dedent\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "\n",
    "    ctx = current_context()\n",
    "\n",
    "    # Load datasets from CSV files\n",
    "    train_df = pd.read_csv(train_dataset.download())\n",
    "    val_df = pd.read_csv(val_dataset.download())\n",
    "    test_df = pd.read_csv(test_dataset.download())\n",
    "\n",
    "    # Create the deck for visualization\n",
    "    deck = Deck(\"Dataset Analysis\")\n",
    "\n",
    "    # Sample reviews from the datasets\n",
    "    train_positive_review = train_df[train_df[\"label\"] == 1].iloc[0][\"text\"]\n",
    "    train_negative_review = train_df[train_df[\"label\"] == 0].iloc[0][\"text\"]\n",
    "    val_positive_review = val_df[val_df[\"label\"] == 1].iloc[0][\"text\"]\n",
    "    val_negative_review = val_df[val_df[\"label\"] == 0].iloc[0][\"text\"]\n",
    "    test_positive_review = test_df[test_df[\"label\"] == 1].iloc[0][\"text\"]\n",
    "    test_negative_review = test_df[test_df[\"label\"] == 0].iloc[0][\"text\"]\n",
    "\n",
    "    # Visualization helper\n",
    "    def plot_label_distribution(df, title, color, output_path):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        df[\"label\"].value_counts().plot(kind=\"bar\", color=color)\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Label\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "\n",
    "    # Plot label distributions\n",
    "    plot_label_distribution(\n",
    "        train_df,\n",
    "        \"Train Data Label Distribution\",\n",
    "        \"skyblue\",\n",
    "        \"/tmp/train_label_distribution.png\",\n",
    "    )\n",
    "    plot_label_distribution(\n",
    "        val_df,\n",
    "        \"Validation Data Label Distribution\",\n",
    "        \"orange\",\n",
    "        \"/tmp/val_label_distribution.png\",\n",
    "    )\n",
    "    plot_label_distribution(\n",
    "        test_df,\n",
    "        \"Test Data Label Distribution\",\n",
    "        \"lightgreen\",\n",
    "        \"/tmp/test_label_distribution.png\",\n",
    "    )\n",
    "\n",
    "    # Convert images to base64 for embedding\n",
    "    def image_to_base64(image_path):\n",
    "        with open(image_path, \"rb\") as img_file:\n",
    "            return base64.b64encode(img_file.read()).decode(\"utf-8\")\n",
    "\n",
    "    train_image_base64 = image_to_base64(\"/tmp/train_label_distribution.png\")\n",
    "    val_image_base64 = image_to_base64(\"/tmp/val_label_distribution.png\")\n",
    "    test_image_base64 = image_to_base64(\"/tmp/test_label_distribution.png\")\n",
    "\n",
    "    # Create HTML report\n",
    "    html_report = dedent(\n",
    "        f\"\"\"\n",
    "    <div style=\"font-family: Arial, sans-serif; line-height: 1.6;\">\n",
    "        <h2 style=\"color: #2C3E50;\">Dataset Analysis</h2>\n",
    "\n",
    "        <h3 style=\"color: #2980B9;\">Training Data Summary</h3>\n",
    "        <img src=\"data:image/png;base64,{train_image_base64}\" alt=\"Train Data Label Distribution\" width=\"600\">\n",
    "        Shape: {train_df.shape} <br>\n",
    "        Label Distribution: {train_df['label'].value_counts()} <br>\n",
    "        <p><strong>Positive Review:</strong> {train_positive_review}</p>\n",
    "        <p><strong>Negative Review:</strong> {train_negative_review}</p>\n",
    "\n",
    "        <h3 style=\"color: #2980B9;\">Validation Data Summary</h3>\n",
    "        <img src=\"data:image/png;base64,{val_image_base64}\" alt=\"Validation Data Label Distribution\" width=\"600\">\n",
    "        Shape: {val_df.shape} <br>\n",
    "        Label Distribution: {val_df['label'].value_counts()} <br>\n",
    "        <p><strong>Positive Review:</strong> {val_positive_review}</p>\n",
    "        <p><strong>Negative Review:</strong> {val_negative_review}</p>\n",
    "\n",
    "        <h3 style=\"color: #2980B9;\">Test Data Summary</h3>\n",
    "        <img src=\"data:image/png;base64,{test_image_base64}\" alt=\"Test Data Label Distribution\" width=\"600\">\n",
    "        Shape: {test_df.shape} <br>\n",
    "        Label Distribution: {test_df['label'].value_counts()} <br>\n",
    "        <p><strong>Positive Review:</strong> {test_positive_review}</p>\n",
    "        <p><strong>Negative Review:</strong> {test_negative_review}</p>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    # Append HTML content to the deck\n",
    "    deck.append(html_report)\n",
    "\n",
    "    # Insert the deck into the context\n",
    "    ctx.decks.insert(0, deck)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile tasks/model.py\n",
    "\"\"\"\n",
    "This file contains the tasks that are used to download, train and evaluate the model.\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "from flytekit.types.directory import FlyteDirectory\n",
    "from flytekit.types.file import FlyteFile\n",
    "from typing_extensions import Annotated\n",
    "from union import Artifact, Deck, Resources, current_context, task\n",
    "from containers import container_image\n",
    "\n",
    "# Define Artifact Specifications\n",
    "FineTunedImdbModel = Artifact(name=\"fine_tuned_Imdb_model\")\n",
    "\n",
    "# ---------------------------\n",
    "# download model\n",
    "# ---------------------------\n",
    "@task(\n",
    "    container_image=container_image,\n",
    "    cache=True,\n",
    "    cache_version=\"1\",\n",
    "    requests=Resources(cpu=\"2\", mem=\"2Gi\"),\n",
    ")\n",
    "def download_model(model_name: str) -> FlyteDirectory:\n",
    "    from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "    working_dir = Path(current_context().working_directory)\n",
    "    saved_model_dir = working_dir / \"saved_model\"\n",
    "    saved_model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        device_map=\"cpu\",\n",
    "        torch_dtype=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    model.save_pretrained(saved_model_dir)\n",
    "    tokenizer.save_pretrained(saved_model_dir)\n",
    "\n",
    "    return FlyteDirectory(saved_model_dir)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# full/lora/qlora fine-tune model\n",
    "# ---------------------------\n",
    "@task(\n",
    "    container_image=container_image,\n",
    "    requests=Resources(cpu=\"4\", mem=\"12Gi\", gpu=\"1\"),\n",
    ")\n",
    "def train_model(\n",
    "    model_dir: FlyteDirectory,\n",
    "    train_dataset: FlyteFile,\n",
    "    val_dataset: FlyteFile,\n",
    "    epochs: int = 3,\n",
    "    tuning_method: str = \"lora\",  # options: \"full\", \"lora\", \"qlora\"\n",
    "    lora_r: int = 8,\n",
    "    lora_alpha: int = 16,\n",
    "    lora_dropout: float = 0.1,\n",
    ") -> Annotated[FlyteDirectory, FineTunedImdbModel]:\n",
    "    import pandas as pd\n",
    "    import torch\n",
    "    from datasets import Dataset\n",
    "    from transformers import (\n",
    "        AutoModelForSequenceClassification,\n",
    "        AutoTokenizer,\n",
    "        Trainer,\n",
    "        TrainingArguments,\n",
    "    )\n",
    "    from peft import prepare_model_for_kbit_training\n",
    "\n",
    "    local_model_dir = model_dir.download()\n",
    "    train_df = pd.read_csv(train_dataset.download()).sample(n=5000, random_state=42)\n",
    "    val_df = pd.read_csv(val_dataset.download()).sample(n=1000, random_state=42)\n",
    "\n",
    "    train_dataset_hf = Dataset.from_pandas(train_df)\n",
    "    val_dataset_hf = Dataset.from_pandas(val_df)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(local_model_dir)\n",
    "\n",
    "    def tokenizer_function(example):\n",
    "        return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "    tokenized_train = train_dataset_hf.map(tokenizer_function)\n",
    "    tokenized_val = val_dataset_hf.map(tokenizer_function)\n",
    "\n",
    "    if tuning_method == \"qlora\":\n",
    "        from transformers import BitsAndBytesConfig\n",
    "        # from peft.utils import prepare_model_for_kbit_training\n",
    "        bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            llm_int8_skip_modules=[\"classifier\", \"pre_classifier\"],\n",
    "        )\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            local_model_dir,\n",
    "            quantization_config=bnb_config,\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            # device_map=\"auto\", # use this for most models if implemented\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(local_model_dir)\n",
    "\n",
    "    if tuning_method in {\"lora\", \"qlora\"}:\n",
    "        from peft import get_peft_model, LoraConfig, TaskType\n",
    "        lora_config = LoraConfig(\n",
    "            task_type=TaskType.SEQ_CLS,\n",
    "            r=lora_r,\n",
    "            lora_alpha=lora_alpha,\n",
    "            lora_dropout=lora_dropout,\n",
    "            target_modules=[\"q_lin\", \"k_lin\", \"v_lin\"],\n",
    "        )\n",
    "\n",
    "        # if tuning_method == \"qlora\":\n",
    "        #     # Ensure LoRA target modules are in float dtype, not int4\n",
    "        #     for name, module in model.named_modules():\n",
    "        #         if any(target in name for target in [\"q_lin\", \"k_lin\", \"v_lin\"]):\n",
    "        #             module.to(torch.bfloat16)\n",
    "\n",
    "        model = get_peft_model(model, lora_config)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_dir=\"./logs\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        greater_is_better=False,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_val,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # Merge LoRA weights into base model\n",
    "    if tuning_method in {\"lora\", \"qlora\"}:\n",
    "        model = model.merge_and_unload()\n",
    "\n",
    "    output_dir = Path(current_context().working_directory) / \"trained_model\"\n",
    "    model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "    #TODO: Save traning type (lora, qlora, full) as artifacts\n",
    "    return FineTunedImdbModel.create_from(output_dir)\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# evaluate model\n",
    "# ---------------------------\n",
    "@task(\n",
    "    container_image=container_image,\n",
    "    enable_deck=True,\n",
    "    requests=Resources(cpu=\"2\", mem=\"12Gi\", gpu=\"1\"),\n",
    ")\n",
    "def evaluate_model(trained_model_dir: FlyteDirectory, test_dataset: FlyteFile) -> dict:\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from datasets import Dataset\n",
    "    from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "    from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
    "    from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    import base64\n",
    "    from union import current_context\n",
    "    from union import Deck\n",
    "    from textwrap import dedent\n",
    "\n",
    "    # Download model locally\n",
    "    local_model_dir = trained_model_dir.download()\n",
    "    ctx = current_context()\n",
    "\n",
    "    # Load model and tokenizer\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        local_model_dir,\n",
    "        torch_dtype=\"auto\",\n",
    "        load_in_4bit=False,  # Important: for evaluation, avoid loading in quantized 4-bit unless you really want to\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(local_model_dir)\n",
    "\n",
    "    # Load and prepare the test dataset\n",
    "    test_df = pd.read_csv(test_dataset.download()).sample(n=1000, random_state=42)\n",
    "\n",
    "    # Use a pipeline for evaluation (bypasses Trainer and works for quantized models)\n",
    "    nlp_pipeline = pipeline(\n",
    "        \"text-classification\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        # device=0 if torch.cuda.is_available() else -1,  # auto-select device\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "    )\n",
    "\n",
    "    # Perform batch inference\n",
    "    predictions = nlp_pipeline(test_df[\"text\"].tolist(), batch_size=8)\n",
    "\n",
    "    # Extract predicted labels\n",
    "    pred_labels = [int(p[\"label\"].split(\"_\")[-1]) if \"label\" in p else 0 for p in predictions]\n",
    "    true_labels = test_df[\"label\"].tolist()\n",
    "\n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(true_labels, pred_labels),\n",
    "        \"f1\": f1_score(true_labels, pred_labels, average=\"weighted\"),\n",
    "        \"precision\": precision_score(true_labels, pred_labels, average=\"weighted\"),\n",
    "        \"recall\": recall_score(true_labels, pred_labels, average=\"weighted\"),\n",
    "        # \"conf_matrix\": confusion_matrix(true_labels, pred_labels)\n",
    "    }\n",
    "\n",
    "    # create visualization deck\n",
    "    deck = Deck(\"Model Evaluation\")\n",
    "\n",
    "    # Generate Confusion Matrix\n",
    "    cm = confusion_matrix(true_labels, pred_labels)\n",
    "    cm_path = f\"/tmp/confusion_matrix.png\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=sorted(set(true_labels)), yticklabels=sorted(set(true_labels)))\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.savefig(cm_path)\n",
    "    plt.close()\n",
    "    \n",
    "    # # Generate ROC Curve\n",
    "    # if len(set(true_labels)) == 2:  # Only for binary classification\n",
    "    #     fpr, tpr, _ = roc_curve(true_labels, probs[:, 1])\n",
    "    #     roc_auc = auc(fpr, tpr)\n",
    "    #     roc_path = f\"tmp/roc_curve.png\"\n",
    "    #     plt.figure(figsize=(8, 6))\n",
    "    #     plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f}')\n",
    "    #     plt.plot([0, 1], [0, 1], color='grey', linestyle='--')\n",
    "    #     plt.xlim([0.0, 1.0])\n",
    "    #     plt.ylim([0.0, 1.05])\n",
    "    #     plt.xlabel('False Positive Rate')\n",
    "    #     plt.ylabel('True Positive Rate')\n",
    "    #     plt.title('Receiver Operating Characteristic')\n",
    "    #     plt.legend(loc=\"lower right\")\n",
    "    #     plt.savefig(roc_path)\n",
    "    #     plt.close()\n",
    "    # else:\n",
    "    #     roc_path = None\n",
    "    \n",
    "    # Convert images to base64 for embedding\n",
    "    def image_to_base64(image_path):\n",
    "        with open(image_path, \"rb\") as img_file:\n",
    "            return base64.b64encode(img_file.read()).decode(\"utf-8\")\n",
    "        \n",
    "    cm_image_base64 = image_to_base64(cm_path)\n",
    "    # roc_image_base64 = image_to_base64(roc_path) if roc_path else None\n",
    "\n",
    "    # Create HTML report\n",
    "    html_report = dedent(\n",
    "        f\"\"\"\n",
    "    <div style=\"font-family: Arial, sans-serif; line-height: 1.6;\">\n",
    "        <h2 style=\"color: #2C3E50;\">Model Evaluation</h2>\n",
    "\n",
    "        <h3 style=\"color: #2980B9;\">Confusion Matrix</h3>\n",
    "        <img src=\"data:image/png;base64,{cm_image_base64}\" alt=\"Confusion Matrix\" width=\"600\">\n",
    "        <h3 style=\"color: #2980B9;\">Model Metrics</h3>\n",
    "        <pre>{metrics}</pre>\n",
    "        \n",
    "    </div>\n",
    "        \"\"\")\n",
    "\n",
    "     # Append HTML content to the deck\n",
    "    deck.append(html_report)\n",
    "    # Insert the deck into the context\n",
    "    ctx.decks.insert(0, deck)\n",
    "\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚀 Serving the Fine-Tuned BERT model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Live App Serving (Beta)\n",
    "\n",
    "Union.ai provides a **simple way to serve your models as a live app**, making it easy to interact with your trained model.  \n",
    "\n",
    "In this example, we'll deploy the model using **Streamlit**, which provides a **simple web interface** for running predictions.  \n",
    "\n",
    "\n",
    "📂 Check out the following files for the model-serving code:  \n",
    "- [`app.py`](app.py) – Defines the **Streamlit-based UI** for interacting with the model.  \n",
    "- [`main.py`](main.py) – Handles **loading the model** and serving it via Union.ai.  \n",
    "\n",
    "Deploy the model by running the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!union deploy apps app.py bert-sentiment-analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the Union platform `Apps` tab to see the status of all apps!\n",
    "\n",
    "Once the app is live, experiment with different inputs and see how your fine-tuned BERT model performs! 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Serving\n",
    "\n",
    "Union.ai also provides a way to serve your models in batch mode. This is useful when you have a large number of predictions to make and you want to do them all at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!union register workflows/batch_inference.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from union.remote import UnionRemote\n",
    "# Create a remote connection\n",
    "remote = UnionRemote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_container(data):\n",
    "\n",
    "    inputs = {\"texts\": data}\n",
    "\n",
    "    workflow = remote.fetch_workflow(name=\"workflows.batch_inference.batch_inference_workflow\")\n",
    "    execution = remote.execute(workflow, inputs=inputs, wait=True) # wait=True will block until the execution is complete\n",
    "\n",
    "    # print(execution.outputs)\n",
    "\n",
    "    return execution.outputs[\"o0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict_with_container([\"I love this movie\",\n",
    "                               \"I hate this movie\"]\n",
    "                               ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⚡ Faster batch serving with Union Actors\n",
    "\n",
    "Union [Actors](https://docs.union.ai/serverless/user-guide/core-concepts/actors/#actors) dramatically reduce the cost of cold starts by maintaining long-running stateful environments that stay ready for use until a defined time-to-live (TTL). This persistent setup eliminates redundant initialization and unlocks several key benefits. This can be especially useful for AI pipelines that benefit from long-running environments, such as large containers, serving models,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_actor(data):\n",
    "\n",
    "    inputs = {\"texts\": data}\n",
    "\n",
    "    workflow = remote.fetch_workflow(name=\"workflows.batch_inference.actor_batch_inference_workflow\")\n",
    "    execution = remote.execute(workflow, inputs=inputs, wait=True) # wait=True will block until the execution is complete\n",
    "\n",
    "    # print(execution.outputs)\n",
    "\n",
    "    return execution.outputs['o0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict_with_actor([\"I love this movie\",\n",
    "                               \"I hate this movie\"]\n",
    "                               ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict_with_actor([\"I love this movie\",\n",
    "                               \"I hate this movie\"]\n",
    "                               ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict_with_actor([\"I love this movie\",\n",
    "                               \"I hate this movie\"]\n",
    "                               ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
